# Pre-Trend-Predictions_AI-Safety-2025-2027
This repository is a **lab-facing capsule**.   It tracks falsifiable predictions about:  - large language model (LLM) safety, - simulation / roleplay overrides, - coherence-over-truth failure modes, - and the epistemic shift in AI/human interaction.
# Academic Integrity Notice

This research code is provided for academic reference.
If you use this work in your research, you MUST:

1. **Cite this repository** in your publications
2. **Credit the original author**
3. **Link to this repository**
4. **Contact me** if building upon this work

Violations will be reported to academic institutions.
