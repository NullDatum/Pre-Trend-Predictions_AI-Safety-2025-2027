# Pre-Trend-Predictions_AI-Safety-2025-2027
This repository is a **lab-facing capsule**.   It tracks falsifiable predictions about:  - large language model (LLM) safety, - simulation / roleplay overrides, - coherence-over-truth failure modes, - and the epistemic shift in AI/human interaction.
